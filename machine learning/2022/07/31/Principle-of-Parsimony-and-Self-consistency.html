<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>On the principles of Parsimony and Self-consistency for the Emergence of Intelligence | Yutian’s Blog</title>
<meta name="generator" content="Jekyll v3.9.4" />
<meta property="og:title" content="On the principles of Parsimony and Self-consistency for the Emergence of Intelligence" />
<meta name="author" content="Yutian Chen" />
<meta property="og:locale" content="en" />
<meta name="description" content="This post is the notes I wrote when reading paper On the principle of Parsimony and Self-consistency for the Emergence of Intelligence arXiv Link. Context and Motivation Key features of Intelligence Agent For an autonomous intelligence agent to survive and function in complex world, it must efficiently and effectively learn models that reflect both its past experience and the current environment being perceived. That is, it must be able to: Utilize knowledge from past experience Reflect on immediate sensory inputs (new perception)" />
<meta property="og:description" content="This post is the notes I wrote when reading paper On the principle of Parsimony and Self-consistency for the Emergence of Intelligence arXiv Link. Context and Motivation Key features of Intelligence Agent For an autonomous intelligence agent to survive and function in complex world, it must efficiently and effectively learn models that reflect both its past experience and the current environment being perceived. That is, it must be able to: Utilize knowledge from past experience Reflect on immediate sensory inputs (new perception)" />
<meta property="og:site_name" content="Yutian’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-07-31T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="On the principles of Parsimony and Self-consistency for the Emergence of Intelligence" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Yutian Chen"},"dateModified":"2022-07-31T00:00:00+00:00","datePublished":"2022-07-31T00:00:00+00:00","description":"This post is the notes I wrote when reading paper On the principle of Parsimony and Self-consistency for the Emergence of Intelligence arXiv Link. Context and Motivation Key features of Intelligence Agent For an autonomous intelligence agent to survive and function in complex world, it must efficiently and effectively learn models that reflect both its past experience and the current environment being perceived. That is, it must be able to: Utilize knowledge from past experience Reflect on immediate sensory inputs (new perception)","headline":"On the principles of Parsimony and Self-consistency for the Emergence of Intelligence","mainEntityOfPage":{"@type":"WebPage","@id":"/machine%20learning/2022/07/31/Principle-of-Parsimony-and-Self-consistency.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"/logo.png"},"name":"Yutian Chen"},"url":"/machine%20learning/2022/07/31/Principle-of-Parsimony-and-Self-consistency.html"}</script>
<!-- End Jekyll SEO tag -->


<link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Yutian's Blog" />





<!-- Google Fonts -->
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open%20Sans|Roboto|Roboto%20Slab|Inconsolata|Dancing%20Script|Noto%20Sans%20SC|Noto%20Sans%20TC|Noto%20Serif%20SC|Noto%20Serif%20TC|Ma%20Shan%20Zheng">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/skin.css">

<!-- Begin selecting skin -->

  <script>
    const hour = (new Date()).getHours();
    let filename = "";
    if (hour >= 5 && hour < 20) {
      filename = "/assets/css/skin-daylight.css";
    } else {
      filename = "/assets/css/skin-daylight.css";
    }
    const elem = document.createElement("link");
    elem.setAttribute("rel", "stylesheet");
    elem.setAttribute("type", "text/css");
    elem.setAttribute("href", filename);
    document.getElementsByTagName("head")[0].appendChild(elem);
  </script>

<!-- End selecting skin -->

<!-- <script async src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script> -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">



<!-- MathJax used to render math equations -->
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

<!-- MS Clarity -->
<script type="text/javascript">
  (function(c,l,a,r,i,t,y){
      c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
      t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
      y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
  })(window, document, "clarity", "script", "eo4n22qg7z");
</script>


  </head>

  <body>
    <div class="site-container">
      <header class="site-header">
        <div class="wrapper">
  <script>
    function clickSidebarButton() {
      const elem = document.getElementById("site-sidebar")
      if (elem.style.display == "none" || elem.style.display == "") {
        elem.style.display = "block";
      } else {
        elem.style.display = "none";
      }
    }
  </script>
  <a class="site-sidebar-button" onclick="clickSidebarButton()"><i class="fa fa-user-circle"></i>
  </a>

  <a class="site-title" rel="author" href="/">Yutian&#39;s Blog</a>

  
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger" title="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
          </svg>
        </span>
      </label>

      <ul class="trigger">
              <li><a class="" href="/about/">About</a></li>
            
              <li><a class="" href="/categories/">Posts</a></li>
            
              <li><a class="" href="/files/">Files</a></li>
            
              <li class="dropdown" href="#">
                <a href="javascript:void(0)" class="dropbtn">More</a>
                <div class="dropdown-content">
                    <a class="" href="/tags/">Tags</a>
                    <a class="" href="/years/">Years</a>
                </div>
              </li>
            </ul>
    </nav>
  
</div>

      </header>
      
      <div class="site-body wrapper">
        <aside class="site-sidebar" id="site-sidebar">
          
            <h3 class="toc-title">Table of Contents</h3>
<nav class="toc-nav">
  <ul class="toc">
  <li><a href="#context-and-motivation">Context and Motivation</a>
    <ul>
      <li><a href="#key-features-of-intelligence-agent">Key features of Intelligence Agent</a></li>
      <li><a href="#problem-with-brute-force-machine-learning">Problem with “Brute-force” Machine Learning</a></li>
      <li><a href="#two-fundamental-principles-in-intelligent-system">Two Fundamental Principles in Intelligent System</a></li>
    </ul>
  </li>
  <li><a href="#principle-of-parsimony">Principle of Parsimony</a>
    <ul>
      <li><a href="#parsimony--most-compressed-representation">Parsimony != Most Compressed Representation</a></li>
      <li><a href="#modeling-parsimony-in-machine-learning">Modeling Parsimony in Machine Learning</a></li>
      <li><a href="#quantifying-parsimony-with-information-theorem">Quantifying Parsimony with Information Theorem</a></li>
      <li><a href="#rate-reduction-of-resulted-feature-space">Rate Reduction of Resulted Feature Space</a></li>
    </ul>
  </li>
  <li><a href="#footnotes">Footnotes</a></li>
</ul>

</nav>

          
        </aside>
        <main class="site-main" id="site-main" aria-label="Content" tabindex="1">
          <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">

    <h1 class="post-title p-name" itemprop="name headline">On the principles of Parsimony and Self-consistency for the Emergence of Intelligence</h1>
    <p class="post-meta"><time class="dt-published" datetime="2022-07-31T00:00:00+00:00" itemprop="datePublished">
        Jul 31, 2022
      </time></p>

  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <blockquote>
  <p>This post is the notes I wrote when reading paper <em>On the principle of Parsimony and Self-consistency for the Emergence of Intelligence</em> <a href="https://arxiv.org/abs/2207.04630">arXiv Link</a>.</p>
</blockquote>

<h2 id="context-and-motivation">Context and Motivation</h2>

<h3 id="key-features-of-intelligence-agent">Key features of Intelligence Agent</h3>

<p>For an autonomous intelligence agent to survive and function in complex world, it must <strong>efficiently</strong> and <strong>effectively</strong> learn models that reflect both its past experience and the current environment being perceived.</p>

<p>That is, it must be able to:</p>

<ol>
  <li>Utilize knowledge from past experience</li>
  <li>Reflect on immediate sensory inputs (new perception)</li>
</ol>

<!--more-->

<h3 id="problem-with-brute-force-machine-learning">Problem with “Brute-force” Machine Learning</h3>

<p>Research in neural science suggests that <strong>structured model</strong><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> is the key for brain’s efficiency and effectiveness in perceiving, predicting and making intelligent decisions.</p>

<p>However, currently most artificial intelligence relies on training “tried-and-tested” models with largely <strong>homogeneous structures</strong> using <strong>brute-force engineering approach</strong>. Such approach has lead to many problems in current machine learning systems:</p>

<ol>
  <li>
    <p>Lack of richness in final learned representations due to <strong>Neural Collapse</strong><sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p>

    <p>Specifically, Neural Collapse refers to a series of phenomenon occurs in the <em>Terminal Phase of Training</em> (TPT)<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> of neural network:</p>

    <ul>
      <li>Variability Collapse: Within-class variation of activations become negligible - the activation value neurons on last layer converges to their class-means</li>
      <li>Simplification to Nearest Class-Center: The network classifier converges to choosing whichever class has the nearest train class-mean in Euclidean distance.</li>
      <li>… (see original paper<sup id="fnref:2:1" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> for the other two Neural Collapse phenomenon)</li>
    </ul>
  </li>
  <li>
    <p>Lack of stability in training due to <strong>Mode Collapse</strong><sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup></p>
  </li>
  <li>
    <p>Lack of adaptiveness and susceptibility due to <strong>Catastrophic Forgetting</strong><sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">5</a></sup></p>
  </li>
  <li>
    <p>Lack of robustness to deformations or adversarial attacks</p>
  </li>
</ol>

<h3 id="two-fundamental-principles-in-intelligent-system">Two Fundamental Principles in Intelligent System</h3>

<p>This paper introduce two fundamental principles: <em>Parsimony</em> and <em>Self-consistency</em> that can govern the function of any intelligent system, artificial or natural.</p>

<p>These two principles respectively aim to answer two fundamental questions about following:</p>

<ol>
  <li>What to learn - what is the objective for learning from data and how can it be measured</li>
  <li>How to learn - how can we achieve such an objective via efficient and effective computation.</li>
</ol>

<figure>
    <img src="https://markdown-img-1304853431.file.myqcloud.com/20220731225118.jpg" />
    <figcaption>Fig 1. How Two Principles of Intelligent System Interact</figcaption>
</figure>

<p>The answers of these two questions are somehow straight forward:</p>

<ol>
  <li>
    <p>What to learn</p>

    <p>The answer to this question fall into <strong>information/coding theory</strong>. We want to accurately quantify and measure the information of data and then seek the most compact representations of the information.</p>
  </li>
  <li>
    <p>How to learn</p>

    <p>The answer to this question falls into <strong>Control/game theory</strong>. These theories provides universal effective computational framework (i.e. closed-loop feedback system) for achieving any measurable objective consistently.</p>
  </li>
</ol>

<h2 id="principle-of-parsimony">Principle of Parsimony</h2>

<blockquote>
  <p><strong>The Principle of Parsimony</strong>: The objective of learning for an intelligent system is to identify low-dimensional structures in observations of the external world and reorganize them in the most <em>compact and structured</em> way.</p>
</blockquote>

<p>Intelligence would be impossible without this principle: If observations of the external world had no low-dimensional structures, there would be nothing worth learning or memorizing!</p>

<h3 id="parsimony--most-compressed-representation">Parsimony != Most Compressed Representation</h3>

<p>While the principle of parsimony do mention the importance of extracting low-dimensional, compact structure from external world, this does not mean the intelligent system should ever achieve the “best possible compression”.</p>

<p>There is no point of an intelligent system to achieve the Shannon compression limit for internal representation of external world data. Such compression itself will be extremely expensive (if it is ever possible) and doesn’t bring any benefit for the intelligent agent itself.</p>

<p>Instead, intelligent agents should pursue a <strong>compact and structured</strong> internal representation.</p>

<ul>
  <li>Compact - means economic to store</li>
  <li>Structured - means efficient to access</li>
</ul>

<h3 id="modeling-parsimony-in-machine-learning">Modeling Parsimony in Machine Learning</h3>

<p>Let $x$ denote the input sensory data (say an image), and $z$ as its internal representation. The sensory data sample $x$ is typically high-dimensional<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">6</a></sup> but has low-dimensional intrinsic structures.</p>

<p>Under this perspective, the purpose of learning is to establish a mapping $f$ with parameter $\theta$ in parametric family $\Theta$, from $\mathbb{R}^D$ to a much lower dimensional representation $z\in \mathbb{R}^d$, that is:</p>

\[x\in \mathbb{R}^D \xrightarrow{f(x, \theta)} z\in \mathbb{R}^d\]

<p>In previous paragraph (<em>Parsimony != Most compressed representation</em>), we mentioned that the goal of learning is to learn the mapping between external world data and compact and structured internal representation. A formal definition to this principle of parsimony can be summarized as:</p>

<ul>
  <li>
    <p><strong>Compression</strong>: Map high-dimensional sensory data $x$ to low dimensional representation $z$</p>

    <p>Otherwise, the model (even the learning process) will be meaningless.</p>
  </li>
  <li>
    <p><strong>Linearization</strong>: Map each class of object distributed on <em>nonlinear</em> submanifold to <em>linear</em> subspace.</p>

    <p>Since linear model are easier to extrapolate than non-linear model.</p>
  </li>
  <li>
    <p><strong>Sparsification</strong>: Map different classes into subspaces with independent or maximally incoherent bases</p>

    <p>Sparsity of internal representation help us classify input sensory data better.</p>
  </li>
</ul>

<figure>
    <img src="https://markdown-img-1304853431.file.myqcloud.com/20220802231946.jpg" />
    <figcaption>Fig 2. Learning, as a process of mapping high-dimensional sensory data to low-dimensional and structured internal representation</figcaption>
</figure>

<p>Such model is called a <strong>linear discriminative representation</strong> (LDR).</p>

<p>A classification model that maps input data into one-hot vectors can be seen as an LDR where target subspace is one-dimensional and orthogonal to each other.</p>

<h3 id="quantifying-parsimony-with-information-theorem">Quantifying Parsimony with Information Theorem</h3>

<p>Given an LDR, we can compute the total “volume” spanned by all features on all subspaces and the sum of volumes spanned by features of each class.</p>

<p>The ratio between these two volumes suggests how good the LDR model is - the larger, the better. That is, we want “<strong>The whole is maximally greater than the sum of its parts</strong>”.</p>

<figure>
    <img src="https://markdown-img-1304853431.file.myqcloud.com/20220806112604.jpg" />
    <figcaption>Fig 3. The higher the ratio between "total volume" and "sum of volume on each subspace" is, the sparser (better) the LDR model is.</figcaption>
</figure>

<p>However, since subspace $S_n$ of class $n$ may not (in fact, almost certainly) have different dimension with feature space $Z$, we will need some method to compare their “volume” under same dimension.</p>

<p>Suppose the feature space $Z$ is filled with spheres with radius of $\varepsilon$ (these spheres are called $\varepsilon$-spheres), each with a volume of $V$. Then we can count the volume of each subspace by this method:</p>

<blockquote>
  <p>For each $\varepsilon$-sphere $P$ in $Z$</p>

  <ul>
    <li>If $P \cap S_n \neq \emptyset$, then volume of $S_n$ will increment by $V$ (the volume of sphere is counted as the volume of $S_n$)</li>
  </ul>
</blockquote>

<p>With this method, we can calculate the ratio between sum of subspaces and the feature space as a whole in this way:</p>

\[\frac{\sum_n{\mathrm{vol}(S_n)}}{\mathrm{vol}(Z)} = 
\frac{\sum_n{\left(\text{#}\mathrm{sphere\;in\;}S_n\right)}}{\text{#}\mathrm{sphere\;in\;}Z}\]

<p>Suppose we want to encode a random sample drawn from feature space $Z$ with precision $\varepsilon$, then we can encode all points in an $\varepsilon$-sphere as  same information. Then, to represent arbitrary sample drawn from $Z$ with precision of $\varepsilon$, we will need $\log_{2}{(\text{#}\mathrm{sphere\;in\;}Z)}$ bits. This value is called the “description length” of $Z$.</p>

<p>Similarly, we can calculate the description length of each feature space.</p>

<p>The description length can also be called as the <strong>“rate distortion”</strong>.</p>

<h3 id="rate-reduction-of-resulted-feature-space">Rate Reduction of Resulted Feature Space</h3>

<p>Let $R$ be the rate distortion of the joint distribution of all features, $Z = \langle z_1, z_2, \cdots, z_n\rangle$ of sampled data $X = \langle x^1, \cdots, x^n \rangle$ from $k$ classes. Let $R^C$ be the average rate distortion for $k$ classes.</p>

<p>For each class, we have a set of feature $Z_i \subseteq Z$, where $Z_1 \cup \cdots Z_k = Z$.</p>

<p>Then, denote $R^C$ as the average rate distortion among $k$ classes,</p>

\[R^C(Z) = \frac{1}{k}\left(
    R(Z_1) + R(Z_2) + \cdots + R(Z_k)
\right)\]

<p>Let $R(Z)$ denote the rate distortion of all features - $Z$.</p>

<p>Then, we can define the <em>rate reduction</em> of resulted feature space of a neural network as</p>

\[\Delta R(Z) = R(Z) - R^C(Z)\]

<p>The larger $\Delta R(Z)$ is, the better the feature representation $Z$ is since larger $\Delta R(Z)$ means subspaces (classes) in this feature representation is more sparse (in the best case, all subspaces should be orthogonal to each other).</p>

<blockquote>
  <p>For principle of self-consistency, see the post <strong>On the principles of Parsimony and Self-consistency for the Emergence of Intelligence (2)</strong>!</p>
</blockquote>

<hr />

<h2 id="footnotes">Footnotes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Study reveals that brain’s world model is highly structured anatomically, that is, there are modular brain areas and <a href="https://neuronaldynamics.epfl.ch/online/Ch12.S1.html">columnar organizations</a> in brain’s biological structure. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>See <a href="https://arxiv.org/abs/2008.08186"><em>Prevalence of Neural Collapse during the terminal phase of deep learning training</em></a> by Papyan et al. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:2:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Terminal Phase of Training: The training process trying to pursue zero-loss after model achieves zero-error. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>Mode Collapse: In GAN training process, the generator network constantly generate very similar or even identical output to the discriminator in order to ensure it is able to “fool” the discriminator network. (<a href="https://machinelearning.wtf/terms/mode-collapse/">source</a>) <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>Catastrophic Forgetting: Neural network completely and abruptly forget previously learned information upon learning new information (<a href="https://en.wikipedia.org/wiki/Catastrophic_interference">source</a>) <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>An image usually have millions of pixels, meaning that $x \in \mathbb{R}^D$ where $D$ has magnitude of $10^6$. <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div>

  <footer class="post-footer">
    
      <div class="post-meta">
        <i class="fa fa-folder-o"></i>
        <ul class="post-taxonomies post-categories">
          
          
            <li class="post-category">
              
              <a href="/categories/#machine-learning">Machine Learning</a>
            </li>
          
        </ul>
      </div>
    

    
      <div class="post-meta">
        <i class="fa fa-tags"></i>
        <ul class="post-taxonomies post-tags">
          
          
            <li class="post-tag">
              
              <a href="/tags/#machine-learning">machine-learning</a>
            </li>
          
            <li class="post-tag">
              
              <a href="/tags/#notes">notes</a>
            </li>
          
        </ul>
      </div>
    

    <nav class="post-pagination" role="navigation">
      
        <a class="post-previous" href="/notes/2022/07/26/why-fp-matters.html">
          <h4 class="post-pagination-label">Prev</h4>
          <span class="post-pagination-title">
            <i class="fa fa-arrow-left"></i> Why Functional Programming Matters

          </span>
        </a>
      

      
        <a class="post-next" href="/computer%20vision/2022/12/01/AirDOS-Dynamic_SLAM_Benefits_from_Articulated_Objects.html">
          <h4 class="post-pagination-label">Next</h4>
          <span class="post-pagination-title">
            AirDOS: Dynamic SLAM Benefits from Articulated Objects
 <i class="fa fa-arrow-right"></i>
          </span>
        </a>
      
    </nav>
  </footer>

  
  
</article>

          <footer class="site-footer">
            <div class="footer-col-wrapper">

  <div class="footer-col">
    <div class="copyright">
      
      
      
      
      <p>Copyright © 2019&nbsp;-&nbsp;2024 Yutian Chen</p>
      
    </div>
    <p>
      Build Version: 08 Jan 2024
    </p>
  </div>

  <div class="footer-col">
    <p>A place for me to Learn, Create and Share</p>
  </div>
</div>

          </footer>
        </main>
      </div>
    </div>
  </body>

</html>
