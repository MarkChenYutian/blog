<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/bc6489d921963ead.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/736bd5ba25105f3a.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-958a1045c5f493e6.js"/><script src="/_next/static/chunks/56bf5c7b-567d655a0c2508ae.js" async=""></script><script src="/_next/static/chunks/416-e71c7162c9bf5c4f.js" async=""></script><script src="/_next/static/chunks/main-app-d9b9a3397237f2d4.js" async=""></script><script src="/_next/static/chunks/386-12980df3d0e2e1b1.js" async=""></script><script src="/_next/static/chunks/697-fdb120d005bfa27e.js" async=""></script><script src="/_next/static/chunks/app/page-49352d76ffbdc088.js" async=""></script><script src="/_next/static/chunks/1727213d-ed770260b52092c7.js" async=""></script><script src="/_next/static/chunks/192-63f0035328ebab3b.js" async=""></script><script src="/_next/static/chunks/app/error-06967b165f29cafe.js" async=""></script><title>Yutian Chen</title><meta name="description" content="A place for me to create and share"/><link rel="manifest" href="/favicon/site.webmanifest" crossorigin="use-credentials"/><meta name="robots" content="index, follow"/><meta property="og:title" content="Yutian&#x27;s Blog"/><meta property="og:description" content="A place for me to create and share"/><meta property="og:url" content="https://www.yutianchen.blog"/><meta property="og:site_name" content="Yutian&#x27;s Blog"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://www.yutianchen.blog/images/og.jpg"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Yutian&#x27;s Blog"/><meta name="twitter:description" content="A place for me to create and share"/><meta name="twitter:image" content="https://www.yutianchen.blog/images/og.jpg"/><link rel="shortcut icon" href="/favicon/favicon-16x16.png"/><link rel="icon" href="/favicon/favicon.ico"/><link rel="apple-touch-icon" href="/favicon/apple-touch-icon.png"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><main><section class="bg-white"><div class="relative flex min-h-screen flex-col text-neutral-700"><nav class="sticky top-0 z-20 flex flex-row flex-nowrap justify-around items-stretch bg-white/60 backdrop-blur-[4px]"><a class="flex-grow text-center font-bold p-3 cursor-pointer border-b-4 hover:border-primary-400 hover:text-primary-500 animated-underline" href="/">About Me</a><a class="flex-grow text-center font-bold p-3 cursor-pointer border-b-4 hover:border-primary-400 hover:text-primary-500 animated-underline" href="/posts">Posts</a><a class="flex-grow text-center font-bold p-3 cursor-pointer border-b-4 hover:border-primary-400 hover:text-primary-500 animated-underline" href="/notes">Notes</a></nav><div class="pb-4 px-6"><div class="relative flex flex-wrap flex-row items-center justify-center w-full"><img alt="Yutian Chen portrait" loading="lazy" width="256" height="256" decoding="async" data-nimg="1" class="rounded-full m-8" style="color:transparent" src="/_next/static/media/Yutian2025_Squared.3fe0d7ca.jpg"/><div class="p-4"><h1 class="text-6xl font-extrabold py-2">Yutian Chen</h1><ul class="mb-8"><li> <a target="_blank" rel="noopener noreferrer" href="mailto:yutianch@andrew.cmu.edu" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail mr-2"><rect width="20" height="16" x="2" y="4" rx="2"></rect><path d="m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"></path></svg> yutianch@andrew.cmu.edu </a></li></ul><div class="flex justify-between items-center flex-wrap"><span class="text-xl font-bold">Carnegie Mellon University</span><span>2021 Aug - 2027 May</span></div><p class="text-lg">MS. Robotics</p><p class="text-lg">BSc. Computer Science, Minor in Mathematical Science</p></div><div class="flex-grow"></div><div class="p-4"><h3 class="font-normal italic">Also find me at ...</h3><ul><li class="text-lg"><a target="_blank" rel="noopener noreferrer" href="https://scholar.google.com/citations?user=9-Cac9MAAAAJ&amp;hl=en" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-graduation-cap mr-2"><path d="M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0z"></path><path d="M22 10v6"></path><path d="M6 12.5V16a6 3 0 0 0 12 0v-3.5"></path></svg> Google Scholar</a></li><li class="text-lg"><a target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/yutian-chen-469602223/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin mr-2"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg> LinkedIn</a></li><li class="text-lg"><a target="_blank" rel="noopener noreferrer" href="https://github.com/MarkChenYutian" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github mr-2"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg> GitHub</a></li></ul></div></div><div class="grid grid-cols-1 md:grid-cols-6"><div class="text-lg homepage-card col-span-1 md:col-span-2 row-span-2"><h2 class="text-3xl py-2 text-primary-900">About Me</h2><p class="break-words hyphens-auto overflow-auto pt-4">I am dedicated to improve the <b>spatial understanding</b> ability of autonomous systems, which requires a combination of geometry and semantic information about the surroundings. My research experience on <b>visual-inertial SLAM</b> at <a target="_blank" rel="noopener noreferrer" href="https://theairlab.org/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">the AirLAB</a> focuses on improving the recognition of scene geometry in adversarial conditions, while my research experience in <b>Natural Language Processing (NLP)</b> and semantic segmentation focuses on grasping and interpreting the semantic of scenes.</p><div class="flex flex-row-reverse pt-4"><a class="inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:ring shadow-sm transition-colors duration-75 px-5 py-3 text-lg md:text-base bg-primary-500 text-white border-primary-600 border hover:bg-primary-600 hover:text-white active:bg-primary-700 disabled:bg-primary-700 disabled:cursor-not-allowed min-w-44 text-center" href="/files/resume.pdf">See My Resume<div class=""><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></div></a></div></div><div class="text-lg homepage-card col-span-1 md:col-span-4 row-span-1"><h2 class="text-3xl py-2 text-primary-900">Recent Research</h2><p class="bg-primary-50 text-primary-600">Our work <i>MAC-VO</i> was nominated as the Best Paper Award Finalist for ICRA 2025!</p><p>Below is a highlight list of my recent works. For a full list of works, please see <a class="animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 text-primary-500" href="#experience-section">Here</a>.</p><ul class="pl-8 py-4"><li><a target="_blank" rel="noopener noreferrer" href="https://air-io.github.io" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-newspaper mr-2"><path d="M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2"></path><path d="M18 14h-8"></path><path d="M15 18h-5"></path><path d="M10 6h8v4h-8V6Z"></path></svg>AirIO: Learning Inertial Odometry with Enhanced IMU Feature Observability</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://mac-vo.github.io/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-newspaper mr-2"><path d="M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2"></path><path d="M18 14h-8"></path><path d="M15 18h-5"></path><path d="M10 6h8v4h-8V6Z"></path></svg>MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://aclanthology.org/2023.emnlp-main.810/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-newspaper mr-2"><path d="M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2"></path><path d="M18 14h-8"></path><path d="M15 18h-5"></path><path d="M10 6h8v4h-8V6Z"></path></svg>Token Prediction as Implicit Classification to Identify LLM-Generated Text</a></li></ul></div><div class="text-lg homepage-card col-span-1 md:col-span-2 row-span-2"><h2 class="text-3xl py-2 text-primary-900">Projects</h2><div class="grid grid-cols-4 justify-center items-center auto-cols-min"><img alt="PyPose Icon" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="inline-block ml-4" style="color:transparent" src="/_next/static/media/pypose.770040ca.jpg"/><h3 class="break-words hyphens-auto overflow-auto text-xl font-semibold col-span-3"><a target="_blank" rel="noopener noreferrer" href="https://pypose.org/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">PyPose</a></h3><p class="col-span-4">PyPose is a Library for Robot Learning with Physics-based Optimization. It supports efficient automatic-differentiation on Lie Group and Lie Algebra. I&#x27;m an active contributor of the PyPose project.</p><div class="col-span-4 p-2"></div><img alt="CMU SCS Icon" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="inline-block ml-4" style="color:transparent" src="/_next/static/media/scslogo_no_outline_simple.8ef58cec.gif"/><h3 class="break-words hyphens-auto overflow-auto text-xl font-semibold pt-4 col-span-3"><a target="_blank" rel="noopener noreferrer" href="https://cs122.andrew.cmu.edu/visualc0/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">C0 Visualizer</a></h3><p class="col-span-4">I designed and implemented the C0 program visualizer in 2022 Summer. It is a virtual machine that executes C0 language (a safe subset of C) and provide visualization and debugging tools for education purpose.</p></div></div><div class="text-lg homepage-card col-span-1 md:col-span-2 row-span-2"><h2 class="text-3xl py-2 text-primary-900">Skills</h2><p class="break-words hyphens-auto overflow-auto font-semibold mt-2">Robotics</p><p>Visual-Inertial SLAM, Computer Vision, Geometric Vision, ROS2, C++</p><p class="break-words hyphens-auto overflow-auto font-semibold mt-4">Deep learning &amp; Artificial Intelligence</p><p>Natural Language Processing, Semantic Segmentation, PyTorch, CUDA, TensorRT, Python, Triton</p><p class="break-words hyphens-auto overflow-auto font-semibold mt-4">Miscellaneous</p><p>React, HTML, CSS, TypeScript, LaTeX, Blender</p></div><div class="text-lg homepage-card col-span-1 md:col-span-2 row-span-1"><h2 class="text-3xl py-2 text-primary-900">Open Source Notes</h2><p class="break-words hyphens-auto overflow-auto">I believe knowledge is most impactful when shared freely. By open-sourcing my notes from high school AP courses to advanced university topics, I aim to improve the accessibility of knowledge for everyone.</p><div class="flex flex-row-reverse pt-4"><a class="inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:ring shadow-sm transition-colors duration-75 px-5 py-3 text-lg md:text-base bg-white text-gray-700 border border-gray-300 hover:text-dark hover:bg-gray-100 active:bg-white/80 disabled:bg-gray-200 disabled:cursor-not-allowed min-w-44 text-center" href="/files">Visit My Notes<div class=""><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></div></a></div></div><div class="text-lg homepage-card col-span-1 md:col-span-4 row-span-4"><h2 class="text-3xl pt-2 text-primary-900" id="experience-section">Experience</h2><ol><li><div class="mt-12"><div class="flex content-between items-start flex-wrap"><img alt="Robot Perception Intern" loading="lazy" width="96" height="96" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/FieldAI_Logo.5e092fef.png"/><div class="ml-4"><p class="text-2xl font-semibold">Robot Perception Intern</p><a target="_blank" rel="noopener noreferrer" href="https://www.fieldai.com" class="cursor-newtab animated-underline custom-link inline-flex items-center focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 font-normal">Field AI Inc.</a></div><div class="flex-grow"></div><span class="font-light">Jun 2025<!-- -->-<!-- -->Aug 2025</span></div><ol class="ml-4 border-l-4 pl-4 my-4"><div class="mb-8"><p>Excited to join Field AI Inc. as a Robot Perception Intern, working with <a target="_blank" rel="noopener noreferrer" href="https://www.kennyjchen.com" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Kenny Chen</a> on robot perception in challenging environments.</p></div></ol></div><div class="mt-12"><div class="flex content-between items-start flex-wrap"><img alt="Learning-based Visual-Inertial SLAM" loading="lazy" width="96" height="96" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/AirLab_Logo.c15be20a.png"/><div class="ml-4"><p class="text-2xl font-semibold">Learning-based Visual-Inertial SLAM</p><a target="_blank" rel="noopener noreferrer" href="https://theairlab.org/" class="cursor-newtab animated-underline custom-link inline-flex items-center focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 font-normal">The AirLab, Robotics Institue, Carnegie Mellon University</a></div><div class="flex-grow"></div><span class="font-light">Sep 2022<!-- -->-<!-- -->Now</span></div><ol class="ml-4 border-l-4 pl-4 my-4"><div class="mb-8"><p>Working with Professor <a target="_blank" rel="noopener noreferrer" href="https://www.ri.cmu.edu/ri-faculty/sebastian-scherer/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Sebastian Scherer</a>, I aimed to construct robust and accurate visual-inertial SLAM system using data-driven approach. I Developed the MAC-VO, a visual odometry that outperforms the state-of-the-art visual odomtries like DPVO by 30% on relative translation error (RTE) and relative rotation error (ROE) in multiple public datasets. I also Deployed the MAC-VO as ROS2 node on Orin-AGX on real drone and speedup the system by 4 times with TensorRT.</p></div><li class="my-1"><a target="_blank" rel="noopener noreferrer" href="https://mac-vo.github.io/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-newspaper mr-2"><path d="M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2"></path><path d="M18 14h-8"></path><path d="M15 18h-5"></path><path d="M10 6h8v4h-8V6Z"></path></svg>AirIO: Learning Inertial Odometry with Enhanced IMU Feature Observability</a></li><li class="my-1"><a target="_blank" rel="noopener noreferrer" href="https://mac-vo.github.io/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-newspaper mr-2"><path d="M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2"></path><path d="M18 14h-8"></path><path d="M15 18h-5"></path><path d="M10 6h8v4h-8V6Z"></path></svg>MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry</a></li><li class="my-1"><a target="_blank" rel="noopener noreferrer" href="https://airimu.github.io/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-newspaper mr-2"><path d="M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2"></path><path d="M18 14h-8"></path><path d="M15 18h-5"></path><path d="M10 6h8v4h-8V6Z"></path></svg>AirIMU: Learning Uncertainty Propagation for Inertial Odometry</a></li><li class="my-1"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2309.13035" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-newspaper mr-2"><path d="M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2"></path><path d="M18 14h-8"></path><path d="M15 18h-5"></path><path d="M10 6h8v4h-8V6Z"></path></svg>PyPose v0.6: The Imperative Programming Interface for Robotics</a></li></ol></div><div class="mt-12"><div class="flex content-between items-start flex-wrap"><img alt="Embodied AI Simulator" loading="lazy" width="96" height="96" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/MIT-IBM-WatsonAI.9337ff61.png"/><div class="ml-4"><p class="text-2xl font-semibold">Embodied AI Simulator</p><a target="_blank" rel="noopener noreferrer" href="https://mitibmwatsonailab.mit.edu/" class="cursor-newtab animated-underline custom-link inline-flex items-center focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 font-normal">IBM-MIT Watson AI Lab</a></div><div class="flex-grow"></div><span class="font-light">Apr 2024<!-- -->-<!-- -->Jan 2025</span></div><ol class="ml-4 border-l-4 pl-4 my-4"><div class="mb-8"><p>Working with Professor <a target="_blank" rel="noopener noreferrer" href="https://people.csail.mit.edu/ganchuang/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Chuang Gan</a>, I developed a data pipeline for City-scale 3D scene reconstruction based on real world satellite/street-view image for multi-agent simulator.</p></div><li class="my-1"><span class="font-light italic">Work In Progress, Currently under double-blind review</span></li></ol></div><div class="mt-12"><div class="flex content-between items-start flex-wrap"><img alt="Generated Text Detection" loading="lazy" width="96" height="96" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/lti.bf03652d.png"/><div class="ml-4"><p class="text-2xl font-semibold">Generated Text Detection</p><a target="_blank" rel="noopener noreferrer" href="https://www.lti.cs.cmu.edu/" class="cursor-newtab animated-underline custom-link inline-flex items-center focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 font-normal">Language Technology Institue, Carnegie Mellon University</a></div><div class="flex-grow"></div><span class="font-light">Mar 2023<!-- -->-<!-- -->Sep 2023</span></div><ol class="ml-4 border-l-4 pl-4 my-4"><div class="mb-8"><p>Working with Professor <a target="_blank" rel="noopener noreferrer" href="http://ayesha.lti.cs.cmu.edu/mlsp/people/rsingh/index.html" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Rita Singh</a> and <a target="_blank" rel="noopener noreferrer" href="https://scholar.google.com/citations?user=IWcGY98AAAAJ&amp;hl=en" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Bhiksha Raj</a>, built a LLM-generated content detector called &quot;LLM-Sentinel&quot;. Reaches 98% accuracy on test dataset and outperform existing content detector by OpenAI and ZeroGPT. Collected the OpenLLMText dataset, a dataset contains 30k human written text from OpenWebText and its corresponding rephrased version by various LLMs such as GPT3.5, LLaMA, PaLM, etc.</p></div><li class="my-1"><a target="_blank" rel="noopener noreferrer" href="https://aclanthology.org/2023.emnlp-main.810/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-newspaper mr-2"><path d="M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2"></path><path d="M18 14h-8"></path><path d="M15 18h-5"></path><path d="M10 6h8v4h-8V6Z"></path></svg>Token Prediction as Implicit Classification to Identify LLM-Generated Text</a></li></ol></div><div class="mt-12"><div class="flex content-between items-start flex-wrap"><img alt="Medical Image Segmentation" loading="lazy" width="96" height="96" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/guangdong_cardiovescular_inst.8136b003.jpg"/><div class="ml-4"><p class="text-2xl font-semibold">Medical Image Segmentation</p><a target="_blank" rel="noopener noreferrer" href="https://www.gdghospital.org.cn/en/introductiontotheinstitute/info_itemId_85.html" class="cursor-newtab animated-underline custom-link inline-flex items-center focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 font-normal">Guangdong Cardiovascular Institute</a></div><div class="flex-grow"></div><span class="font-light">Dec 2018<!-- -->-<!-- -->Jan 2020</span></div><ol class="ml-4 border-l-4 pl-4 my-4"><div class="mb-8"><p>Mentored by Professor <a target="_blank" rel="noopener noreferrer" href="https://engineering.nd.edu/faculty/yiyu-shi/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Yiyu Shi</a> and <a target="_blank" rel="noopener noreferrer" href="https://xiaoweixu.github.io" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Xiaowei Xu</a>, I proposed an encoder-decoder architecture to perform semantic segmentation on cardiac MRI sequence. By introducing Temporal constraint on segmentation result, the model improved the accuracy by 2% on ACDC Dataset comparing to the baseline model.</p></div><li class="my-1"><a target="_blank" rel="noopener noreferrer" href="https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2022.804442/full" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-newspaper mr-2"><path d="M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2"></path><path d="M18 14h-8"></path><path d="M15 18h-5"></path><path d="M10 6h8v4h-8V6Z"></path></svg>Myocardial Segmentation of Cardiac MRI Sequences With Temporal Consistency for Coronary Artery Disease Diagnosis</a></li></ol></div></li></ol></div><div class="text-lg homepage-card col-span-1 md:col-span-2 row-span-1"><h2 class="text-3xl py-2 text-primary-900">Courses</h2><ol class="my-2 ml-4 list-disc"><li>16-833 Localization and Mapping</li><li>16-385 Computer Vision</li><li>15-451 Algorithm Design &amp; Analysis</li><li>15-418 Parallel Computer Architecture and Programming</li><li>11-777 Multi-Modal Machine Learning</li><li>10-708 Probablistic Graphical Model</li><li>11-785 Intro to Deep Learning</li></ol></div></div></div></div></section><div><footer class="min-h-24 items-center justify-center py-12 text-center border-t-2 border-slate-200">© <!-- -->2025<!-- --> By<!-- --> <a target="_blank" rel="noopener noreferrer" href="https://www.yutianchen.blog/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Yutian Chen</a></footer></div></main><script src="/_next/static/chunks/webpack-958a1045c5f493e6.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/bc6489d921963ead.css\",\"style\"]\n2:HL[\"/_next/static/css/736bd5ba25105f3a.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[6628,[],\"\"]\n5:I[2386,[\"386\",\"static/chunks/386-12980df3d0e2e1b1.js\",\"697\",\"static/chunks/697-fdb120d005bfa27e.js\",\"931\",\"static/chunks/app/page-49352d76ffbdc088.js\"],\"\"]\n6:I[4697,[\"386\",\"static/chunks/386-12980df3d0e2e1b1.js\",\"697\",\"static/chunks/697-fdb120d005bfa27e.js\",\"931\",\"static/chunks/app/page-49352d76ffbdc088.js\"],\"Image\"]\n7:I[242,[],\"\"]\n8:I[3154,[\"407\",\"static/chunks/1727213d-ed770260b52092c7.js\",\"192\",\"static/chunks/192-63f0035328ebab3b.js\",\"601\",\"static/chunks/app/error-06967b165f29cafe.js\"],\"default\"]\n9:I[3562,[],\"\"]\nb:I[2769,[],\"\"]\nc:[]\n"])</script><script>self.__next_f.push([1,"0:[\"$\",\"$L3\",null,{\"buildId\":\"BR43TOxD1x_foGUvzoWxe\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"\"],\"initialTree\":[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"__PAGE__\",{},[[\"$L4\",[\"$\",\"main\",null,{\"children\":[[\"$\",\"section\",null,{\"className\":\"bg-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"relative flex min-h-screen flex-col text-neutral-700\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"sticky top-0 z-20 flex flex-row flex-nowrap justify-around items-stretch bg-white/60 backdrop-blur-[4px]\",\"children\":[[\"$\",\"$L5\",null,{\"href\":\"/\",\"className\":\"flex-grow text-center font-bold p-3 cursor-pointer border-b-4 hover:border-primary-400 hover:text-primary-500 animated-underline\",\"children\":\"About Me\"}],[\"$\",\"$L5\",null,{\"href\":\"/posts\",\"className\":\"flex-grow text-center font-bold p-3 cursor-pointer border-b-4 hover:border-primary-400 hover:text-primary-500 animated-underline\",\"children\":\"Posts\"}],[\"$\",\"$L5\",null,{\"href\":\"/notes\",\"className\":\"flex-grow text-center font-bold p-3 cursor-pointer border-b-4 hover:border-primary-400 hover:text-primary-500 animated-underline\",\"children\":\"Notes\"}]]}],[\"$\",\"div\",null,{\"className\":\"pb-4 px-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"relative flex flex-wrap flex-row items-center justify-center w-full\",\"children\":[[\"$\",\"$L6\",null,{\"alt\":\"Yutian Chen portrait\",\"src\":\"/_next/static/media/Yutian2025_Squared.3fe0d7ca.jpg\",\"width\":256,\"height\":256,\"className\":\"rounded-full m-8\"}],[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-extrabold py-2\",\"children\":\"Yutian Chen\"}],[\"$\",\"ul\",null,{\"className\":\"mb-8\",\"children\":[\"$\",\"li\",null,{\"children\":[\" \",[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"mailto:yutianch@andrew.cmu.edu\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-mail mr-2\",\"children\":[[\"$\",\"rect\",\"18n3k1\",{\"width\":\"20\",\"height\":\"16\",\"x\":\"2\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"1ocrg3\",{\"d\":\"m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7\"}],\"$undefined\"]}],\" yutianch@andrew.cmu.edu \"]}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex justify-between items-center flex-wrap\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-xl font-bold\",\"children\":\"Carnegie Mellon University\"}],[\"$\",\"span\",null,{\"children\":\"2021 Aug - 2027 May\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-lg\",\"children\":\"MS. Robotics\"}],[\"$\",\"p\",null,{\"className\":\"text-lg\",\"children\":\"BSc. Computer Science, Minor in Mathematical Science\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex-grow\"}],[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-normal italic\",\"children\":\"Also find me at ...\"}],[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"className\":\"text-lg\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://scholar.google.com/citations?user=9-Cac9MAAAAJ\u0026hl=en\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-graduation-cap mr-2\",\"children\":[[\"$\",\"path\",\"j76jl0\",{\"d\":\"M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0z\"}],[\"$\",\"path\",\"1lu8f3\",{\"d\":\"M22 10v6\"}],[\"$\",\"path\",\"1r8lef\",{\"d\":\"M6 12.5V16a6 3 0 0 0 12 0v-3.5\"}],\"$undefined\"]}],\" Google Scholar\"]}]}],[\"$\",\"li\",null,{\"className\":\"text-lg\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://www.linkedin.com/in/yutian-chen-469602223/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-linkedin mr-2\",\"children\":[[\"$\",\"path\",\"c2jq9f\",{\"d\":\"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z\"}],[\"$\",\"rect\",\"mk3on5\",{\"width\":\"4\",\"height\":\"12\",\"x\":\"2\",\"y\":\"9\"}],[\"$\",\"circle\",\"bt5ra8\",{\"cx\":\"4\",\"cy\":\"4\",\"r\":\"2\"}],\"$undefined\"]}],\" LinkedIn\"]}]}],[\"$\",\"li\",null,{\"className\":\"text-lg\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://github.com/MarkChenYutian\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github mr-2\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}],\" GitHub\"]}]}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-lg homepage-card col-span-1 md:col-span-2 row-span-2\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl py-2 text-primary-900\",\"children\":\"About Me\"}],[\"$\",\"p\",null,{\"className\":\"break-words hyphens-auto overflow-auto pt-4\",\"children\":[\"I am dedicated to improve the \",[\"$\",\"b\",null,{\"children\":\"spatial understanding\"}],\" ability of autonomous systems, which requires a combination of geometry and semantic information about the surroundings. My research experience on \",[\"$\",\"b\",null,{\"children\":\"visual-inertial SLAM\"}],\" at \",[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://theairlab.org/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"the AirLAB\"}],\" focuses on improving the recognition of scene geometry in adversarial conditions, while my research experience in \",[\"$\",\"b\",null,{\"children\":\"Natural Language Processing (NLP)\"}],\" and semantic segmentation focuses on grasping and interpreting the semantic of scenes.\"]}],[\"$\",\"div\",null,{\"className\":\"flex flex-row-reverse pt-4\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/files/resume.pdf\",\"className\":\"inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:ring shadow-sm transition-colors duration-75 px-5 py-3 text-lg md:text-base bg-primary-500 text-white border-primary-600 border hover:bg-primary-600 hover:text-white active:bg-primary-700 disabled:bg-primary-700 disabled:cursor-not-allowed min-w-44 text-center\",\"children\":[\"$undefined\",\"See My Resume\",[\"$\",\"div\",null,{\"className\":\"\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":\"1em\",\"height\":\"1em\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-right\",\"children\":[[\"$\",\"path\",\"1ays0h\",{\"d\":\"M5 12h14\"}],[\"$\",\"path\",\"xquz4c\",{\"d\":\"m12 5 7 7-7 7\"}],\"$undefined\"]}]}]]}]}]]}],[\"$\",\"div\",null,{\"className\":\"text-lg homepage-card col-span-1 md:col-span-4 row-span-1\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl py-2 text-primary-900\",\"children\":\"Recent Research\"}],[\"$\",\"p\",null,{\"className\":\"bg-primary-50 text-primary-600\",\"children\":[\"Our work \",[\"$\",\"i\",null,{\"children\":\"MAC-VO\"}],\" was nominated as the Best Paper Award Finalist for ICRA 2025!\"]}],[\"$\",\"p\",null,{\"children\":[\"Below is a highlight list of my recent works. For a full list of works, please see \",[\"$\",\"$L5\",null,{\"href\":\"#experience-section\",\"className\":\"animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 text-primary-500\",\"children\":\"Here\"}],\".\"]}],[\"$\",\"ul\",null,{\"className\":\"pl-8 py-4\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://air-io.github.io\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-newspaper mr-2\",\"children\":[[\"$\",\"path\",\"7pis2x\",{\"d\":\"M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2\"}],[\"$\",\"path\",\"sponae\",{\"d\":\"M18 14h-8\"}],[\"$\",\"path\",\"95g1m2\",{\"d\":\"M15 18h-5\"}],[\"$\",\"path\",\"smlsk5\",{\"d\":\"M10 6h8v4h-8V6Z\"}],\"$undefined\"]}],\"AirIO: Learning Inertial Odometry with Enhanced IMU Feature Observability\"]}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://mac-vo.github.io/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-newspaper mr-2\",\"children\":[[\"$\",\"path\",\"7pis2x\",{\"d\":\"M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2\"}],[\"$\",\"path\",\"sponae\",{\"d\":\"M18 14h-8\"}],[\"$\",\"path\",\"95g1m2\",{\"d\":\"M15 18h-5\"}],[\"$\",\"path\",\"smlsk5\",{\"d\":\"M10 6h8v4h-8V6Z\"}],\"$undefined\"]}],\"MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry\"]}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://aclanthology.org/2023.emnlp-main.810/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-newspaper mr-2\",\"children\":[[\"$\",\"path\",\"7pis2x\",{\"d\":\"M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2\"}],[\"$\",\"path\",\"sponae\",{\"d\":\"M18 14h-8\"}],[\"$\",\"path\",\"95g1m2\",{\"d\":\"M15 18h-5\"}],[\"$\",\"path\",\"smlsk5\",{\"d\":\"M10 6h8v4h-8V6Z\"}],\"$undefined\"]}],\"Token Prediction as Implicit Classification to Identify LLM-Generated Text\"]}]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"text-lg homepage-card col-span-1 md:col-span-2 row-span-2\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl py-2 text-primary-900\",\"children\":\"Projects\"}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-4 justify-center items-center auto-cols-min\",\"children\":[[\"$\",\"$L6\",null,{\"alt\":\"PyPose Icon\",\"src\":\"/_next/static/media/pypose.770040ca.jpg\",\"width\":\"44\",\"height\":\"44\",\"className\":\"inline-block ml-4\"}],[\"$\",\"h3\",null,{\"className\":\"break-words hyphens-auto overflow-auto text-xl font-semibold col-span-3\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://pypose.org/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"PyPose\"}]}],[\"$\",\"p\",null,{\"className\":\"col-span-4\",\"children\":\"PyPose is a Library for Robot Learning with Physics-based Optimization. It supports efficient automatic-differentiation on Lie Group and Lie Algebra. I'm an active contributor of the PyPose project.\"}],[\"$\",\"div\",null,{\"className\":\"col-span-4 p-2\"}],[\"$\",\"$L6\",null,{\"alt\":\"CMU SCS Icon\",\"src\":\"/_next/static/media/scslogo_no_outline_simple.8ef58cec.gif\",\"width\":\"44\",\"height\":\"44\",\"className\":\"inline-block ml-4\"}],[\"$\",\"h3\",null,{\"className\":\"break-words hyphens-auto overflow-auto text-xl font-semibold pt-4 col-span-3\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://cs122.andrew.cmu.edu/visualc0/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"C0 Visualizer\"}]}],[\"$\",\"p\",null,{\"className\":\"col-span-4\",\"children\":\"I designed and implemented the C0 program visualizer in 2022 Summer. It is a virtual machine that executes C0 language (a safe subset of C) and provide visualization and debugging tools for education purpose.\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"text-lg homepage-card col-span-1 md:col-span-2 row-span-2\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl py-2 text-primary-900\",\"children\":\"Skills\"}],[\"$\",\"p\",null,{\"className\":\"break-words hyphens-auto overflow-auto font-semibold mt-2\",\"children\":\"Robotics\"}],[\"$\",\"p\",null,{\"children\":\"Visual-Inertial SLAM, Computer Vision, Geometric Vision, ROS2, C++\"}],[\"$\",\"p\",null,{\"className\":\"break-words hyphens-auto overflow-auto font-semibold mt-4\",\"children\":\"Deep learning \u0026 Artificial Intelligence\"}],[\"$\",\"p\",null,{\"children\":\"Natural Language Processing, Semantic Segmentation, PyTorch, CUDA, TensorRT, Python, Triton\"}],[\"$\",\"p\",null,{\"className\":\"break-words hyphens-auto overflow-auto font-semibold mt-4\",\"children\":\"Miscellaneous\"}],[\"$\",\"p\",null,{\"children\":\"React, HTML, CSS, TypeScript, LaTeX, Blender\"}]]}],[\"$\",\"div\",null,{\"className\":\"text-lg homepage-card col-span-1 md:col-span-2 row-span-1\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl py-2 text-primary-900\",\"children\":\"Open Source Notes\"}],[\"$\",\"p\",null,{\"className\":\"break-words hyphens-auto overflow-auto\",\"children\":\"I believe knowledge is most impactful when shared freely. By open-sourcing my notes from high school AP courses to advanced university topics, I aim to improve the accessibility of knowledge for everyone.\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-row-reverse pt-4\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/files\",\"className\":\"inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:ring shadow-sm transition-colors duration-75 px-5 py-3 text-lg md:text-base bg-white text-gray-700 border border-gray-300 hover:text-dark hover:bg-gray-100 active:bg-white/80 disabled:bg-gray-200 disabled:cursor-not-allowed min-w-44 text-center\",\"children\":[\"$undefined\",\"Visit My Notes\",[\"$\",\"div\",null,{\"className\":\"\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":\"1em\",\"height\":\"1em\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-right\",\"children\":[[\"$\",\"path\",\"1ays0h\",{\"d\":\"M5 12h14\"}],[\"$\",\"path\",\"xquz4c\",{\"d\":\"m12 5 7 7-7 7\"}],\"$undefined\"]}]}]]}]}]]}],[\"$\",\"div\",null,{\"className\":\"text-lg homepage-card col-span-1 md:col-span-4 row-span-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl pt-2 text-primary-900\",\"id\":\"experience-section\",\"children\":\"Experience\"}],[\"$\",\"ol\",null,{\"children\":[\"$\",\"li\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"mt-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex content-between items-start flex-wrap\",\"children\":[[\"$\",\"$L6\",null,{\"alt\":\"Robot Perception Intern\",\"src\":{\"src\":\"/_next/static/media/FieldAI_Logo.5e092fef.png\",\"height\":256,\"width\":256,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAYAAADED76LAAAAzElEQVR42j2Ova5BURSE1zo5916Rq9BIqFQaCZ1EofAEEq+glUi8gWjUNB7DA6BWKFUSLaJDgrN/zvEFsZPJ2jN7ZvbSS6+dFmvG4n1FvHuABKTASh/3figm6kocdxDkC/eatUSDTQjJSewRrUEMQEhgqtY0JImrGIxFEAy/7wa/V2d/uO8IHgMagBWEkzDV2y2zDi+x25pHk4EsIRN1pBxGb7OYiuiHgMqZmuiP2iHmOUunMeUJpJgFFc61VR7hbmI+f777576Q6DZ4AuJokmYmgyEMAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"width\":96,\"height\":96}],[\"$\",\"div\",null,{\"className\":\"ml-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-2xl font-semibold\",\"children\":\"Robot Perception Intern\"}],[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://www.fieldai.com\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 font-normal\",\"children\":\"Field AI Inc.\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex-grow\"}],[\"$\",\"span\",null,{\"className\":\"font-light\",\"children\":[\"Jun 2025\",\"-\",\"Aug 2025\"]}]]}],[\"$\",\"ol\",null,{\"className\":\"ml-4 border-l-4 pl-4 my-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Excited to join Field AI Inc. as a Robot Perception Intern, working with \",[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://www.kennyjchen.com\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"Kenny Chen\"}],\" on robot perception in challenging environments.\"]}]}],[]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex content-between items-start flex-wrap\",\"children\":[[\"$\",\"$L6\",null,{\"alt\":\"Learning-based Visual-Inertial SLAM\",\"src\":{\"src\":\"/_next/static/media/AirLab_Logo.c15be20a.png\",\"height\":83,\"width\":130,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAmUlEQVR42mMAgSNyho5APG2/poXOIRUT/8MKRiVHZA1agZiBoT0pjfG4gFbgWQYpi0sMDF5XGBjsTzMoxJ7g04wBYgaGmvRs8eqMbP+M/CLH8qzcRSXZeTNzcwtcy7Jy/Sszc4QZ0vOLBICSPkDMkJVXuCQ7r3AWUEEnkK4BYgaGvNwCdqBAARC7ANlOQNodiGcDcV1ubgEDAIRmOfwQN837AAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":5},\"width\":96,\"height\":96}],[\"$\",\"div\",null,{\"className\":\"ml-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-2xl font-semibold\",\"children\":\"Learning-based Visual-Inertial SLAM\"}],[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://theairlab.org/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 font-normal\",\"children\":\"The AirLab, Robotics Institue, Carnegie Mellon University\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex-grow\"}],[\"$\",\"span\",null,{\"className\":\"font-light\",\"children\":[\"Sep 2022\",\"-\",\"Now\"]}]]}],[\"$\",\"ol\",null,{\"className\":\"ml-4 border-l-4 pl-4 my-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Working with Professor \",[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://www.ri.cmu.edu/ri-faculty/sebastian-scherer/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"Sebastian Scherer\"}],\", I aimed to construct robust and accurate visual-inertial SLAM system using data-driven approach. I Developed the MAC-VO, a visual odometry that outperforms the state-of-the-art visual odomtries like DPVO by 30% on relative translation error (RTE) and relative rotation error (ROE) in multiple public datasets. I also Deployed the MAC-VO as ROS2 node on Orin-AGX on real drone and speedup the system by 4 times with TensorRT.\"]}]}],[[\"$\",\"li\",\"0\",{\"className\":\"my-1\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://mac-vo.github.io/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-newspaper mr-2\",\"children\":[[\"$\",\"path\",\"7pis2x\",{\"d\":\"M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2\"}],[\"$\",\"path\",\"sponae\",{\"d\":\"M18 14h-8\"}],[\"$\",\"path\",\"95g1m2\",{\"d\":\"M15 18h-5\"}],[\"$\",\"path\",\"smlsk5\",{\"d\":\"M10 6h8v4h-8V6Z\"}],\"$undefined\"]}],\"AirIO: Learning Inertial Odometry with Enhanced IMU Feature Observability\"]}]}],[\"$\",\"li\",\"1\",{\"className\":\"my-1\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://mac-vo.github.io/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-newspaper mr-2\",\"children\":[[\"$\",\"path\",\"7pis2x\",{\"d\":\"M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2\"}],[\"$\",\"path\",\"sponae\",{\"d\":\"M18 14h-8\"}],[\"$\",\"path\",\"95g1m2\",{\"d\":\"M15 18h-5\"}],[\"$\",\"path\",\"smlsk5\",{\"d\":\"M10 6h8v4h-8V6Z\"}],\"$undefined\"]}],\"MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry\"]}]}],[\"$\",\"li\",\"2\",{\"className\":\"my-1\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://airimu.github.io/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-newspaper mr-2\",\"children\":[[\"$\",\"path\",\"7pis2x\",{\"d\":\"M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2\"}],[\"$\",\"path\",\"sponae\",{\"d\":\"M18 14h-8\"}],[\"$\",\"path\",\"95g1m2\",{\"d\":\"M15 18h-5\"}],[\"$\",\"path\",\"smlsk5\",{\"d\":\"M10 6h8v4h-8V6Z\"}],\"$undefined\"]}],\"AirIMU: Learning Uncertainty Propagation for Inertial Odometry\"]}]}],[\"$\",\"li\",\"3\",{\"className\":\"my-1\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://arxiv.org/abs/2309.13035\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-newspaper mr-2\",\"children\":[[\"$\",\"path\",\"7pis2x\",{\"d\":\"M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2\"}],[\"$\",\"path\",\"sponae\",{\"d\":\"M18 14h-8\"}],[\"$\",\"path\",\"95g1m2\",{\"d\":\"M15 18h-5\"}],[\"$\",\"path\",\"smlsk5\",{\"d\":\"M10 6h8v4h-8V6Z\"}],\"$undefined\"]}],\"PyPose v0.6: The Imperative Programming Interface for Robotics\"]}]}]]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex content-between items-start flex-wrap\",\"children\":[[\"$\",\"$L6\",null,{\"alt\":\"Embodied AI Simulator\",\"src\":{\"src\":\"/_next/static/media/MIT-IBM-WatsonAI.9337ff61.png\",\"height\":152,\"width\":152,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAYAAADED76LAAAAtElEQVR42l3NMUoDQRjF8f+bDJMYBbEQxCaLCmrjKSzEW1h6He/geext7MRKiVkXZufb+YSQTSC/9j3eE3tOnjz+JJzKWnxt7h8OZrftsZ3F96vH9jn4+UUuk1ZygCho8PpdJ2l2lJefi/wVb6ykMhaADPRIIRSzu27lp4NVYywIBHgQyXouuyWHw0CVGBem4MmlNLUSm+5XyWtwdhcfgj9HcW59e73Kc8DZEHveFi9R1bbJP2lHSLZURrSSAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"width\":96,\"height\":96}],[\"$\",\"div\",null,{\"className\":\"ml-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-2xl font-semibold\",\"children\":\"Embodied AI Simulator\"}],[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://mitibmwatsonailab.mit.edu/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 font-normal\",\"children\":\"IBM-MIT Watson AI Lab\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex-grow\"}],[\"$\",\"span\",null,{\"className\":\"font-light\",\"children\":[\"Apr 2024\",\"-\",\"Jan 2025\"]}]]}],[\"$\",\"ol\",null,{\"className\":\"ml-4 border-l-4 pl-4 my-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Working with Professor \",[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://people.csail.mit.edu/ganchuang/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"Chuang Gan\"}],\", I developed a data pipeline for City-scale 3D scene reconstruction based on real world satellite/street-view image for multi-agent simulator.\"]}]}],[[\"$\",\"li\",\"0\",{\"className\":\"my-1\",\"children\":[\"$\",\"span\",\"0\",{\"className\":\"font-light italic\",\"children\":\"Work In Progress, Currently under double-blind review\"}]}]]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex content-between items-start flex-wrap\",\"children\":[[\"$\",\"$L6\",null,{\"alt\":\"Generated Text Detection\",\"src\":{\"src\":\"/_next/static/media/lti.bf03652d.png\",\"height\":256,\"width\":256,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAIAAABLbSncAAAAsklEQVR42h1O2wqCQBD1/z8ggsK8rD0UWOLtwSSDerUHL0is5BItrZWY0Zuu7e5hmDNzDjMciVI6shrHun6mWc6GYRhYl6igT9dlWR7H56Ztudf3EqMHhOZs7siKIy88YHwx5hdwH12DXbha24rm68CSF4XrldFBelfV7XgKVM0Fhg+Wjg6Y2iDEX70wtk3TV/Vwa20m0x8hTOSGiFRfYJkWxR0htlJm8LgChJAkSbkq8Ad03aUisGa1BwAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":8},\"width\":96,\"height\":96}],[\"$\",\"div\",null,{\"className\":\"ml-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-2xl font-semibold\",\"children\":\"Generated Text Detection\"}],[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://www.lti.cs.cmu.edu/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 font-normal\",\"children\":\"Language Technology Institue, Carnegie Mellon University\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex-grow\"}],[\"$\",\"span\",null,{\"className\":\"font-light\",\"children\":[\"Mar 2023\",\"-\",\"Sep 2023\"]}]]}],[\"$\",\"ol\",null,{\"className\":\"ml-4 border-l-4 pl-4 my-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Working with Professor \",[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"http://ayesha.lti.cs.cmu.edu/mlsp/people/rsingh/index.html\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"Rita Singh\"}],\" and \",[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://scholar.google.com/citations?user=IWcGY98AAAAJ\u0026hl=en\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"Bhiksha Raj\"}],\", built a LLM-generated content detector called \\\"LLM-Sentinel\\\". Reaches 98% accuracy on test dataset and outperform existing content detector by OpenAI and ZeroGPT. Collected the OpenLLMText dataset, a dataset contains 30k human written text from OpenWebText and its corresponding rephrased version by various LLMs such as GPT3.5, LLaMA, PaLM, etc.\"]}]}],[[\"$\",\"li\",\"0\",{\"className\":\"my-1\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://aclanthology.org/2023.emnlp-main.810/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-newspaper mr-2\",\"children\":[[\"$\",\"path\",\"7pis2x\",{\"d\":\"M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2\"}],[\"$\",\"path\",\"sponae\",{\"d\":\"M18 14h-8\"}],[\"$\",\"path\",\"95g1m2\",{\"d\":\"M15 18h-5\"}],[\"$\",\"path\",\"smlsk5\",{\"d\":\"M10 6h8v4h-8V6Z\"}],\"$undefined\"]}],\"Token Prediction as Implicit Classification to Identify LLM-Generated Text\"]}]}]]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex content-between items-start flex-wrap\",\"children\":[[\"$\",\"$L6\",null,{\"alt\":\"Medical Image Segmentation\",\"src\":{\"src\":\"/_next/static/media/guangdong_cardiovescular_inst.8136b003.jpg\",\"height\":200,\"width\":200,\"blurDataURL\":\"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAoKCgoKCgsMDAsPEA4QDxYUExMUFiIYGhgaGCIzICUgICUgMy03LCksNy1RQDg4QFFeT0pPXnFlZXGPiI+7u/sBCgoKCgoKCwwMCw8QDhAPFhQTExQWIhgaGBoYIjMgJSAgJSAzLTcsKSw3LVFAODhAUV5PSk9ecWVlcY+Ij7u7+//CABEIAAgACAMBIgACEQEDEQH/xAAoAAEBAAAAAAAAAAAAAAAAAAAABwEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAKuKP//EAB0QAAIBBAMAAAAAAAAAAAAAAAECEgADBBEhUeH/2gAIAQEAAT8AQZqZZU7a0XlLfEevK//EABgRAAIDAAAAAAAAAAAAAAAAAAERAAIh/9oACAECAQE/ALFrAJ//xAAVEQEBAAAAAAAAAAAAAAAAAAAAAf/aAAgBAwEBPwCP/9k=\",\"blurWidth\":8,\"blurHeight\":8},\"width\":96,\"height\":96}],[\"$\",\"div\",null,{\"className\":\"ml-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-2xl font-semibold\",\"children\":\"Medical Image Segmentation\"}],[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://www.gdghospital.org.cn/en/introductiontotheinstitute/info_itemId_85.html\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 font-normal\",\"children\":\"Guangdong Cardiovascular Institute\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex-grow\"}],[\"$\",\"span\",null,{\"className\":\"font-light\",\"children\":[\"Dec 2018\",\"-\",\"Jan 2020\"]}]]}],[\"$\",\"ol\",null,{\"className\":\"ml-4 border-l-4 pl-4 my-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Mentored by Professor \",[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://engineering.nd.edu/faculty/yiyu-shi/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"Yiyu Shi\"}],\" and \",[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://xiaoweixu.github.io\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"Xiaowei Xu\"}],\", I proposed an encoder-decoder architecture to perform semantic segmentation on cardiac MRI sequence. By introducing Temporal constraint on segmentation result, the model improved the accuracy by 2% on ACDC Dataset comparing to the baseline model.\"]}]}],[[\"$\",\"li\",\"0\",{\"className\":\"my-1\",\"children\":[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2022.804442/full\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-newspaper mr-2\",\"children\":[[\"$\",\"path\",\"7pis2x\",{\"d\":\"M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2\"}],[\"$\",\"path\",\"sponae\",{\"d\":\"M18 14h-8\"}],[\"$\",\"path\",\"95g1m2\",{\"d\":\"M15 18h-5\"}],[\"$\",\"path\",\"smlsk5\",{\"d\":\"M10 6h8v4h-8V6Z\"}],\"$undefined\"]}],\"Myocardial Segmentation of Cardiac MRI Sequences With Temporal Consistency for Coronary Artery Disease Diagnosis\"]}]}]]]}]]}]]}]}]]}],[\"$\",\"div\",null,{\"className\":\"text-lg homepage-card col-span-1 md:col-span-2 row-span-1\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl py-2 text-primary-900\",\"children\":\"Courses\"}],[\"$\",\"ol\",null,{\"className\":\"my-2 ml-4 list-disc\",\"children\":[[\"$\",\"li\",null,{\"children\":\"16-833 Localization and Mapping\"}],[\"$\",\"li\",null,{\"children\":\"16-385 Computer Vision\"}],[\"$\",\"li\",null,{\"children\":\"15-451 Algorithm Design \u0026 Analysis\"}],[\"$\",\"li\",null,{\"children\":\"15-418 Parallel Computer Architecture and Programming\"}],[\"$\",\"li\",null,{\"children\":\"11-777 Multi-Modal Machine Learning\"}],[\"$\",\"li\",null,{\"children\":\"10-708 Probablistic Graphical Model\"}],[\"$\",\"li\",null,{\"children\":\"11-785 Intro to Deep Learning\"}]]}]]}]]}]]}]]}]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"footer\",null,{\"className\":\"min-h-24 items-center justify-center py-12 text-center border-t-2 border-slate-200\",\"children\":[\"© \",2025,\" By\",\" \",[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://www.yutianchen.blog/\",\"className\":\"cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0\",\"children\":\"Yutian Chen\"}]]}]}]]}],null],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/bc6489d921963ead.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/736bd5ba25105f3a.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$8\",\"errorStyles\":[],\"errorScripts\":[],\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"main\",null,{\"children\":[\"$\",\"section\",null,{\"className\":\"bg-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"layout flex min-h-screen flex-col items-center justify-center text-center text-black\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 24 24\",\"className\":\"drop-shadow-glow animate-flicker text-red-500\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M4.00001 20V14C4.00001 9.58172 7.58173 6 12 6C16.4183 6 20 9.58172 20 14V20H21V22H3.00001V20H4.00001ZM6.00001 14H8.00001C8.00001 11.7909 9.79087 10 12 10V8C8.6863 8 6.00001 10.6863 6.00001 14ZM11 2H13V5H11V2ZM19.7782 4.80761L21.1924 6.22183L19.0711 8.34315L17.6569 6.92893L19.7782 4.80761ZM2.80762 6.22183L4.22183 4.80761L6.34315 6.92893L4.92894 8.34315L2.80762 6.22183Z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":60,\"width\":60,\"xmlns\":\"http://www.w3.org/2000/svg\"}],[\"$\",\"h1\",null,{\"className\":\"mt-8 text-4xl md:text-6xl\",\"children\":\"Page Not Found\"}],[\"$\",\"a\",null,{\"href\":\"/\",\"children\":\"Back to home\"}]]}]}]}],\"notFoundStyles\":[]}]}]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$La\"],\"globalErrorComponent\":\"$b\",\"missingSlots\":\"$Wc\"}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Yutian Chen\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"A place for me to create and share\"}],[\"$\",\"link\",\"4\",{\"rel\":\"manifest\",\"href\":\"/favicon/site.webmanifest\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"meta\",\"5\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Yutian's Blog\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"A place for me to create and share\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:url\",\"content\":\"https://www.yutianchen.blog\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:site_name\",\"content\":\"Yutian's Blog\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image\",\"content\":\"https://www.yutianchen.blog/images/og.jpg\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"Yutian's Blog\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"A place for me to create and share\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image\",\"content\":\"https://www.yutianchen.blog/images/og.jpg\"}],[\"$\",\"link\",\"17\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon/favicon-16x16.png\"}],[\"$\",\"link\",\"18\",{\"rel\":\"icon\",\"href\":\"/favicon/favicon.ico\"}],[\"$\",\"link\",\"19\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon/apple-touch-icon.png\"}]]\n4:null\n"])</script></body></html>